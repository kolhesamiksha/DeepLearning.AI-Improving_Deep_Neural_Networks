# DeepLearning.AI-Improving_Deep_Neural_Networks
This repository contains assignments completed in Improving Deep Learning Models- Hyperparameter_Tuning, Regularization, Optimization, Course By Andrew ng 

![images](https://user-images.githubusercontent.com/73512374/191227645-ecd14833-36aa-4615-a4a9-a976bc99475a.png)


Content Covered:
1. Understand industry best-practices for building deep learning applications.
2. Be able to effectively use the common neural network "tricks", including initialization, L2 and dropout regularization, Batch normalization, gradient checking,
3. Be able to implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence.
4. Understand new best-practices for the deep learning era of how to set up train/dev/test sets and analyze bias/variance
5. Be able to implement a neural network in TensorFlow.
